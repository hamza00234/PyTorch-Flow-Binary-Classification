{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-Y2u-S81h9A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data collection and representation, use linear regression"
      ],
      "metadata": {
        "id": "6wZShYrf2nG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight=0.7\n",
        "bias=0.3\n",
        "#create\n",
        "X=torch.arange(0,1,0.02).unsqueeze(dim=1)\n",
        "y=weight*X + bias\n",
        "X[:10],y[:10]\n"
      ],
      "metadata": {
        "id": "6VqodKIx3DWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train, validation, test\n",
        "train_split=int(0.8*len(X))\n",
        "X_train,y_train=X[:train_split],y[:train_split]\n",
        "X_test,y_test=X[train_split:],y[train_split:]\n"
      ],
      "metadata": {
        "id": "tpxu2fhw3iE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred(train_data=X_train, train_labels=y_train,test_labels=y_test, predictions=None):\n",
        "  plt.figure(figsize=(10,7))\n",
        "  plt.scatter(X_train,y_train,c=\"b\",s=4,label=\"training data\")\n",
        "  #predictions\n",
        "  if predictions is not None:\n",
        "    plt.scatter(X_test,predictions,c=\"r\",s=4,label=\"predictions\")\n",
        "    plt.scatter(X_test,y_test,c=\"g\",s=4,label=\"test data\")\n",
        "  else:\n",
        "    plt.scatter(X_test,y_test,c=\"g\",s=4,label=\"test data\")\n",
        "  plt.legend(prop={\"size\":14})"
      ],
      "metadata": {
        "id": "rI1HgYo40RpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred(X_train, y_train, y_test)"
      ],
      "metadata": {
        "id": "o_v7UT_o_mSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class linear_regression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights=nn.Parameter(torch.randn(1,\n",
        "                                           requires_grad=True,\n",
        "                                           dtype=torch.float))\n",
        "    self.bias=nn.Parameter(torch.randn(1,\n",
        "                                       requires_grad=True,\n",
        "                                       dtype=torch.float))\n",
        "\n",
        "    #forward method\n",
        "  def forward(self,x:torch.Tensor)->torch.Tensor:#-<- x is the input data\n",
        "    return self.weights*x + self.bias #linear regression formula\n"
      ],
      "metadata": {
        "id": "qEjpmhHJ_8_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### explanation: model starts with random vlaues(weights,bias), look at trianing data and adjustng the random values to better represent (or get close to) the ideal values, using:\n",
        "- gradient descent(requires_grad=true)\n",
        "- back propagation"
      ],
      "metadata": {
        "id": "B_97--PoB460"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##pytorch models building essentials\n",
        "* torch.nn- contains all of the building for computational graphs(neural network)\n",
        "* torch.nn.Parameter- what parameters should out model try and learn, often pytorch layer from torch.nn will set these\n",
        "* torch.nn.Module- the base class for all neural network modules, you should overwrite forward()\n",
        "* torch.optim- this where the optimizer in pytorch live, they will help with gradient descent\n",
        "* def forward()- all nn.modules requires you to overwrite forward(), this method defines what happens in forward computation"
      ],
      "metadata": {
        "id": "12idz__VDPye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### for data ready most useful are:\n",
        "* torchvision.transforms\n",
        "* torch.utils.data.Dataset\n",
        "* torch.utils.data.DataLoader"
      ],
      "metadata": {
        "id": "S8A9BLDOEu7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### for build/pick a pretained model:\n",
        "* torch.nn\n",
        "* torch.nn.Modules\n",
        "* torchvision.models\n",
        "* torch.optim"
      ],
      "metadata": {
        "id": "-5hvLuTBFAL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluate mode:\n",
        "* torchmetrics\n",
        "\n",
        "### improve through experimentations:\n",
        "* torch.utils.tensorboard"
      ],
      "metadata": {
        "id": "AgUwQSj8FMo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check content of pytorch model\n",
        "torch.manual_seed(42)#to get same parameters\n",
        "#create instance\n",
        "model_0=linear_regression()\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "id": "OYrNSGr_EJ3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "RUv7UTPQG7Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions using torch.no_grad()\n",
        "with torch.no_grad():\n",
        "  y_pred=model_0(X_test)\n",
        "\n",
        "y_pred"
      ],
      "metadata": {
        "id": "eb_Jv3BDHB0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this code is equivalent to the above code the difference\n",
        "# is that the above code doesnt track gradient,\n",
        "# less memory as it is not needed in prediction, only in training:\n",
        "# y_pred=model_0(X_test) # This line is not needed and causes the error\n",
        "y_pred = model_0(X_test).detach() # Detach the tensor to remove gradient tracking\n",
        "y_pred"
      ],
      "metadata": {
        "id": "233qzStIK0xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred(predictions=y_pred)"
      ],
      "metadata": {
        "id": "2uA5ojStICVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions using torch.inference_mode()\n",
        "with torch.no_grad():\n",
        "  y_pred=model_0(X_test)\n",
        "\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "udir1dt0MDMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When to use torch.inference_mode()\n",
        "\n",
        "Use this after training is completely done — when you’re deploying or running the model for pure inference (predictions only)."
      ],
      "metadata": {
        "id": "AFPXrPQUL7U1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When to use torch.no_grad()\n",
        "\n",
        "Use this when you’re still in a training workflow, but want to momentarily stop gradient tracking"
      ],
      "metadata": {
        "id": "5evRnc8PL8XI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training model"
      ],
      "metadata": {
        "id": "L-xX_9oiCZqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### difference between cost function and loss function:\n",
        "* Loss function: measures how wrong the model’s prediction is for one sample (or one batch)\n",
        "\n",
        "* Cost function: the average (or total) of all the losses across the entire dataset.\n",
        "It represents the overall error of the model"
      ],
      "metadata": {
        "id": "fvlP_CYqCyAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### optimizer: takes into account the loss of a model and adjusts the models parameter"
      ],
      "metadata": {
        "id": "q0noRH9tDS16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loss function\n",
        "loss=nn.L1Loss()\n",
        "#optimizer (stochastic gradient descent)\n",
        "optimizer=torch.optim.SGD(params=model_0.parameters(),\n",
        "                          lr=0.01) #leaning rate"
      ],
      "metadata": {
        "id": "o6Pk_aLGKGXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training and testing loop\n",
        "1. loop through the data\n",
        "2. forward pass (data move through the forward function)-forward propagation\n",
        "3. calculate loss(compare forward pass predictions to actual labels)\n",
        "4. optimizer zero grad\n",
        "5. loss backward- backpropagation to calculate gradient of each parameters of our model with respect to the loss\n",
        "6. optimizer step(gradient descent)"
      ],
      "metadata": {
        "id": "5QLk8DZzEue9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "#build training loop\n",
        "epochs=100 #one loop through data, hyper parameter because we have set it\n",
        "\n",
        "#track values\n",
        "epoch_count=[]\n",
        "loss_values=[]\n",
        "test_loss_values=[]\n",
        "#loop through data\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #set to training mode\n",
        "  model_0.train()\n",
        "  #forward pass\n",
        "  y_pred=model_0(X_train)\n",
        "  #calculate loss\n",
        "  loss_train=loss(y_pred,y_train)\n",
        "  #print(loss_train)\n",
        "  #optimizer\n",
        "  optimizer.zero_grad()#reset optimizer to start fresh in each loop\n",
        "  #loss backward\n",
        "  loss_train.backward()\n",
        "  #optimizer step\n",
        "  optimizer.step()\n",
        "\n",
        "  #testing\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    #forward pass\n",
        "    test_pred=model_0(X_test)\n",
        "    #calculate loss\n",
        "    test_loss=loss(test_pred,y_test)\n",
        "    #print(test_loss)\n",
        "    if epoch%10==0:\n",
        "      epoch_count.append(epoch)\n",
        "      loss_values.append(loss_train)\n",
        "      test_loss_values.append(test_loss)\n",
        "      print(f\"epoch: {epoch} | loss:{loss} | testloss: {test_loss}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZkXF8Tl5ErnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot loss curve\n",
        "plt.plot(epoch_count,torch.tensor(loss_values).numpy(),label=\"train loss\")\n",
        "plt.plot(epoch_count, torch.tensor(test_loss_values).numpy(), label=\"test loss\" )\n",
        "plt.title(\"loss curve\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "4z4mSJ7QMAyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* eval mode-> turns of gradient tracking\n",
        "* training mode-> turns on gradient tracking"
      ],
      "metadata": {
        "id": "eFYoKwlcGV8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds_new=model_0(X_test)"
      ],
      "metadata": {
        "id": "RA-Eftd_I_g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred(predictions=y_preds_new)"
      ],
      "metadata": {
        "id": "coxx-BCbJKyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "MSNRlaSaJWQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save model\n",
        "1. torch.save()\n",
        "2. torch.load- load a saved object\n",
        "3. torch.nn.Module.load_state_dict()-> allows to load a models daved in state dictionary"
      ],
      "metadata": {
        "id": "GLuD8xhUo5vS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "from pathlib import Path\n",
        "#create directory\n",
        "model_path=Path(\"models\")\n",
        "model_path.mkdir(parents=True,exist_ok=True)\n",
        "#create model save path\n",
        "model_name=\"01_pytorch_workflow_linearR.pth\"\n",
        "model_save_path=model_path/model_name\n",
        "model_save_path\n",
        "#Save state dict\n",
        "torch.save(obj=model_0.state_dict(),\n",
        "           f=model_save_path)"
      ],
      "metadata": {
        "id": "o2wjhF_-JdbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load in model state dict:\n",
        "loaded_model=linear_regression()\n",
        "loaded_model.load_state_dict(torch.load(f=model_save_path))\n",
        "loaded_model.state_dict()"
      ],
      "metadata": {
        "id": "te5yftqQqPzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZeKYr7iTk-c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}