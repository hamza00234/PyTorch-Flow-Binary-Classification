{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. make classification data ready"
      ],
      "metadata": {
        "id": "qYPJ0pDTVJ-p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykH3NpOOU2Ho"
      },
      "outputs": [],
      "source": [
        "import  sklearn\n",
        "from sklearn.datasets import make_circles"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#binary classification\n",
        "x,y=make_circles(1000, noise=0.03, random_state=42)"
      ],
      "metadata": {
        "id": "ZSRQ5sDeVWNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x),len(y)"
      ],
      "metadata": {
        "id": "ek4IfN2vVkaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:5])"
      ],
      "metadata": {
        "id": "DoFs4fkSVohj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[:5])"
      ],
      "metadata": {
        "id": "EG3Aa38RVshO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "circles=pd.DataFrame({\"X1\": x[:,0],\n",
        "                      \"X2\": x[:,1],\n",
        "                      \"label\":y})\n",
        "circles.head(10)"
      ],
      "metadata": {
        "id": "OQkfXuLCV-eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(x=circles[\"X1\"],\n",
        "            y=circles[\"X2\"],\n",
        "            c=circles[\"label\"],\n",
        "            cmap=plt.cm.RdYlBu)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lXVRNy-fWV3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# classify data as red or blue"
      ],
      "metadata": {
        "id": "-NhM84PoWmZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#turn data to tensors & create train,test splits\n",
        "x.shape,y.shape"
      ],
      "metadata": {
        "id": "W4OXfu5rWrH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "8wOwahCrXJkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.from_numpy(x).type(torch.float)\n",
        "y=torch.from_numpy(y).type(torch.float)"
      ],
      "metadata": {
        "id": "U0P-001UXjji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test, y_train,y_test=train_test_split(x,\n",
        "                                                y,\n",
        "                                                test_size=0.2,\n",
        "                                                random_state=42)\n"
      ],
      "metadata": {
        "id": "hxFuARk1XzzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. model"
      ],
      "metadata": {
        "id": "Y3fFFgisYcAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "nl8q5X-5Yge7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#construct model:\n",
        "class CircleModelV0(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #create nn linear layers\n",
        "        self.layer_1=nn.Linear(in_features=2,out_features=5)#takes in 2 features, outputs 5\n",
        "        self.layer_2=nn.Linear(in_features=5,out_features=1)#takes 5 from previous layer and outputs 1\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.layer_2(self.layer_1(x))# x-> layer 1->layer 2->output\n",
        "\n",
        "model_0=CircleModelV0().to(device)\n",
        "model_0\n",
        "\n"
      ],
      "metadata": {
        "id": "xpA2lIE-Y32l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of layers controls how deep the network is — how many levels of abstraction it can learn.\n",
        "\n",
        "Fewer layers → simpler patterns (like straight lines).\n",
        "\n",
        "More layers → more complex patterns (like curves, shapes, or images).\n",
        "\n",
        "out_features (neurons in a layer) control how wide each layer is — how much learning capacity it has at that level.\n",
        "\n",
        "Fewer neurons → simpler relationships, faster training.\n",
        "\n",
        "More neurons → can capture richer patterns but may overfit if too many."
      ],
      "metadata": {
        "id": "LkDGn84hajjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#replicate using nn.Sequential(), automatically codes class, equivalent to class CircleModelV0\n",
        "model_0=nn.Sequential(\n",
        "    nn.Linear(in_features=2,out_features=5),\n",
        "    nn.Linear(in_features=5,out_features=1)\n",
        ").to(device)\n",
        "model_0"
      ],
      "metadata": {
        "id": "f13xHU0NakkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()\n",
        "#layer1-> 2*5=10 which are 0.weight, 5 output tensors of first layer(0.bias)"
      ],
      "metadata": {
        "id": "5qOXSbc_hOJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make predicitons\n",
        "with torch.inference_mode():\n",
        "  untrained_preds=model_0(x_test.to(device))\n",
        "\n",
        "untrained_preds[:10], untrained_preds.shape, y_test[:10]"
      ],
      "metadata": {
        "id": "3q22Hf1_hTsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##loss function and optimizer\n",
        "- loss for classification is not the same as for regression:\n",
        "- binary cross entropy/categorical cross entropy"
      ],
      "metadata": {
        "id": "jpyGJ2_ioGEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use torch.optim and torch.nn.BEXWithLogitsLoss\n",
        "\n",
        "#loss\n",
        "loss_fn=nn.BCEWithLogitsLoss()#has sigmoid activation function built in\n",
        "\n",
        "#optimizer\n",
        "optimizer=torch.optim.SGD(params=model_0.parameters(),\n",
        "                          lr=0.1)"
      ],
      "metadata": {
        "id": "jw14sM_tjBaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate accuracy\n",
        "def acc_fn(y_true,y_pred):\n",
        "  correct=torch.eq(y_true, y_pred).sum().item()\n",
        "  acc=correct/len(y_pred)*100\n",
        "  return acc\n"
      ],
      "metadata": {
        "id": "CCxCcPAMu3Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train model"
      ],
      "metadata": {
        "id": "H3x30LXXvoe1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### steps:\n",
        "raw logits-> prediction probabilities -> prediction labels\n",
        "- convert logits to probbilities by passing them through some kinf of activation function(sigmoid for binary classification and softmax for multiclass classification)\n",
        "- then convert models prediction probabilities to prediction labels by either rounding them or taking the argmax()"
      ],
      "metadata": {
        "id": "G2vqr3Lpv1c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train and test loop\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)#for doing operations on cuda device\n",
        "epochs=1000\n",
        "\n",
        "x_train,y_train=x_train.to(device), y_train.to(device)\n",
        "x_test,y_test=x_test.to(device), y_test.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_0.train()\n",
        "\n",
        "  #forward pass\n",
        "  y_logits=model_0(x_train).squeeze()\n",
        "  y_pred=torch.round(torch.sigmoid(y_logits))\n",
        "\n",
        "  #calculate loss\n",
        "  loss=loss_fn(y_logits,y_train)#requires raw logits\n",
        "  acc= acc_fn(y_train, y_pred)\n",
        "\n",
        "  #optimizer\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  #loss backwards(backprop)\n",
        "  loss.backward()\n",
        "\n",
        "  #optimizer step(gradient descent)\n",
        "  optimizer.step()\n",
        "\n",
        "  ###test\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_logits=model_0(x_test).squeeze()\n",
        "    test_pred=torch.round(torch.sigmoid(test_logits))\n",
        "\n",
        "    #calculate loss\n",
        "    test_loss=loss_fn(test_logits,y_test)\n",
        "    test_acc=acc_fn(y_test,test_pred)\n",
        "\n",
        "    if epoch%10==0:\n",
        "      print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Acc: {acc:.2f}% | Test Loss: {test_loss:.5f} | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1UX_lG-w02dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visulaize to fix\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "#download helper function\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists\")\n",
        "else:\n",
        "  print(\"downloading helper_functions.py\")\n",
        "  request=requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/refs/heads/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\",\"wb\") as f:\n",
        "    f.write(request.content)\n",
        "\n",
        "from helper_functions import plot_predictions, plot_decision_boundary"
      ],
      "metadata": {
        "id": "24itdZmj4uMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_decision_boundary\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plot_decision_boundary(model_0, x_train, y_train)\n",
        "plt.subplot(1,2,2)\n",
        "plot_decision_boundary(model_0, x_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j_OF5J6D6u_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###improving model(improve through experimentation), options:\n",
        "1. add more layers\n",
        "2. add more hidden units- from 5 to 10\n",
        "3. fit for longer\n",
        "4. change the activation functions\n",
        "5. change learning rate\n",
        "6. change the loss function\n",
        "\n"
      ],
      "metadata": {
        "id": "KQQjBBia71yU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#problem is using linear, build model with non-linearity\n",
        "class CircleModelV1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1=nn.Linear(in_features=2,out_features=32)\n",
        "    self.layer_2=nn.Linear(in_features=32,out_features=32)\n",
        "    self.layer_3=nn.Linear(in_features=32,out_features=1)\n",
        "    self.relu=nn.ReLU()#non linear activation function\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
        "\n",
        "model_1=CircleModelV1().to(device)\n",
        "model_1\n",
        "\n"
      ],
      "metadata": {
        "id": "kZvDAZcc7yOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ReLU helps the model learn features.\n",
        "- Sigmoid (or Softmax) helps interpret the result as a probability."
      ],
      "metadata": {
        "id": "xeHU2cxi7jdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setup loss and optimizer\n",
        "loss_fn=nn.BCEWithLogitsLoss()\n",
        "optimizer=torch.optim.SGD(model_1.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "79lhR9lu8MF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "epochs=1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_1.train()\n",
        "  #forward pass\n",
        "  y_logits=model_1(x_train).squeeze()\n",
        "  y_pred=torch.round(torch.sigmoid(y_logits))\n",
        "  #loss\n",
        "  loss=loss_fn(y_logits,y_train)\n",
        "  #acc\n",
        "  acc=acc_fn(y_train,y_pred)\n",
        "\n",
        "  #optimizer\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  #loss backwards\n",
        "  loss.backward()\n",
        "\n",
        "  #optimizer step\n",
        "  optimizer.step()\n",
        "\n",
        "  model_1.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_logits=model_1(x_test).squeeze()\n",
        "    test_pred=torch.round(torch.sigmoid(test_logits))\n",
        "    test_loss=loss_fn(test_logits,y_test)\n",
        "    test_acc=acc_fn(y_test,test_pred)\n",
        "\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Acc: {acc:.2f}% | Test Loss: {test_loss:.5f} | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9QF4NTQS8fit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "  y_preds=torch.round(torch.sigmoid(model_1(x_test.to(device)))).squeeze()\n",
        "\n",
        "y_preds[:10], y_test[:10]"
      ],
      "metadata": {
        "id": "5RDMaR85-Aie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plot_decision_boundary(model_0, x_train, y_train)\n",
        "plt.subplot(1,2,2)\n",
        "plot_decision_boundary(model_1, x_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mvLo5yog-cg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#mutliclass classification problem"
      ],
      "metadata": {
        "id": "ndVONZ-TA7Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create toy multiclass dataset\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#set hyperparameters from documentation\n",
        "Num_classes=4\n",
        "Num_features=2\n",
        "\n",
        "\n",
        "\n",
        "#create\n",
        "X_blob, y_blob=make_blobs(n_samples=1000,\n",
        "                          n_features=Num_features,\n",
        "                          centers=Num_classes,\n",
        "                          cluster_std=1.5,\n",
        "                          random_state=42)\n",
        "\n",
        "#turn to tensors\n",
        "X_blob=torch.from_numpy(X_blob).type(torch.float)\n",
        "y_blob=torch.from_numpy(y_blob).type(torch.LongTensor)\n",
        "\n",
        "#split\n",
        "X_train, X_test, y_train, y_test=train_test_split(X_blob,\n",
        "                                                  y_blob,\n",
        "                                                  test_size=0.2,\n",
        "                                                  random_state=42)\n",
        "\n",
        "#visualize\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(X_blob[:,0], X_blob[:,1], c=y_blob, cmap=plt.cm.RdYlBu)"
      ],
      "metadata": {
        "id": "U2JFpGeY_46c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build model\n",
        "#output features=number of classes\n",
        "class Multiclass(nn.Module):\n",
        "  def __init__(self, input_features, output_features, hidden_units=8):\n",
        "    super().__init__()\n",
        "    self.linear_layer_stack=nn.Sequential(\n",
        "        nn.Linear(in_features=input_features, out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_features)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.linear_layer_stack(x)\n",
        "\n",
        "model_2=Multiclass(input_features=2,\n",
        "                   output_features=4,\n",
        "                   hidden_units=8).to(device)\n",
        "model_2\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o-bFaOegLGl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss function, optimizer\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(model_2.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "6sKuCkumPU4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have a dataset that have imbalance number of samples for each class add weights to crossentropyloss"
      ],
      "metadata": {
        "id": "vf2j-M1oPjzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "epochs=100\n",
        "\n",
        "X_train, X_test, y_train, y_test= X_train.to(device), X_test.to(device), y_train.to(device), y_test.to(device)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_2.train()\n",
        "  #forward pass\n",
        "  y_logits=model_2(X_train)\n",
        "  y_pred=torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
        "  #loss\n",
        "  loss=loss_fn(y_logits,y_train)\n",
        "  acc=acc_fn(y_train,y_pred)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  model_2.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_logits=model_2(X_test)\n",
        "    test_pred=torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
        "    test_loss=loss_fn(test_logits,y_test)\n",
        "    test_acc=acc_fn(y_test,test_pred)\n",
        "    if epoch%10==0:\n",
        "      print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Acc: {acc:.2f}% | Test Loss: {test_loss} | test acc:{test_acc}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "tLNY3sS8PzVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plot_decision_boundary(model_2, X_train, y_train)\n",
        "plt.subplot(1,2,2)\n",
        "plot_decision_boundary(model_2, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jxcrJDswejul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "74CtxyukfMM-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}